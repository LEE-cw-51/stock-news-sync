import sys
import os
import time
import logging
from datetime import datetime

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 1. ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(current_dir)
if root_dir not in sys.path:
    sys.path.append(root_dir)

from dotenv import load_dotenv
load_dotenv()

from backend.config.tickers import (
    NAME_MAP, US_CANDIDATES, KR_CANDIDATES, 
    MY_PORTFOLIO, WATCHLIST, MACRO_KEYWORDS
)
from backend.services.db_service import DBService
from backend.services.market_service import get_market_indices, get_top_volume_stocks
from backend.services.news_service import get_tavily_news
from backend.services.ai_service import generate_ai_summary

def run_sync_engine_once():
    logger.info("[Start] Data Sync at %s", datetime.now())

    db_svc = DBService()
    now_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    # [A] ì§€ìˆ˜ ë° ì£¼ìš” ì§€í‘œ ì—…ë°ì´íŠ¸
    logger.info("[Step A] ì§€ìˆ˜ ë° ì£¼ìš” ì§€í‘œ ìˆ˜ì§‘ ì‹œì‘")
    indices_config = {
        "market_indices/domestic": { "KOSPI": "^KS11", "KOSDAQ": "^KQ11" },
        "market_indices/global": { "S&P500": "^GSPC", "NASDAQ": "^IXIC" },
        "key_indicators": {
            "USD_KRW": "USDKRW=X", "US_10Y": "^TNX", "BTC": "BTC-USD", "Gold": "GC=F"
        }
    }
    for path, items in indices_config.items():
        updates = get_market_indices(items)
        for key in updates:
            updates[key]["updated_at"] = now_str
        db_svc.update_market_indices(path, updates)

    # [B] ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ë° êµ¬ì¡°í™”
    logger.info("[Step B] ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    frontend_feed = { "portfolio": [], "watchlist": [], "macro": [] }
    ai_contexts = { "macro": "", "portfolio": "", "watchlist": "" }

    # 1. ê±°ì‹œê²½ì œ ë‰´ìŠ¤
    for keyword in MACRO_KEYWORDS:
        context, links = get_tavily_news(keyword)
        if context:
            ai_contexts["macro"] += f"\n[Keyword: {keyword}]\n{context}\n"
            for item in links:
                news_item = {
                    "title": item.get("title"),
                    "link": item.get("url"),
                    "name": "Macro",
                    "pubDate": item.get("published_date")
                }
                frontend_feed["macro"].append(news_item)
        time.sleep(1)

    # 2. ì¢…ëª© ë°ì´í„° ë° ë‰´ìŠ¤ ìˆ˜ì§‘
    us_stocks = get_top_volume_stocks(US_CANDIDATES, 15)
    kr_stocks = get_top_volume_stocks(KR_CANDIDATES, 15)
    stock_data_map = {}

    for item in (us_stocks + kr_stocks):
        symbol = item['symbol']
        info = NAME_MAP.get(symbol, {"name": symbol, "sector": "ê¸°íƒ€"})
        safe_key = symbol.replace(".", "_")

        stock_data_map[safe_key] = {
            "symbol": symbol, "name": info['name'], "price": round(item['price'], 2),
            "change_percent": item['change_percent'], "volume": int(item['volume']),
            "sector": info.get('sector', 'ë¯¸ë¶„ë¥˜')
        }

        category = None
        if symbol in MY_PORTFOLIO: category = "portfolio"
        elif symbol in WATCHLIST: category = "watchlist"

        if category:
            context, links = get_tavily_news(info['name'])
            if context:
                ai_contexts[category] += f"\n[{info['name']}]\n{context}\n"
                for link_data in links:
                    news_item = {
                        "title": link_data.get("title"),
                        "link": link_data.get("url"),
                        "name": info['name'],
                        "pubDate": link_data.get("published_date")
                    }
                    frontend_feed[category].append(news_item)
            time.sleep(1)

    # [C] AI ìš”ì•½ ìƒì„±
    logger.info("[Step C] AI ìš”ì•½ ìƒì„± ì‹œì‘")
    ai_summaries = {
        "macro":     generate_ai_summary("ê¸€ë¡œë²Œ ê²½ì œ",   ai_contexts["macro"],     category="macro"),
        "portfolio": generate_ai_summary("ë‚´ í¬íŠ¸í´ë¦¬ì˜¤", ai_contexts["portfolio"], category="portfolio"),
        "watchlist": generate_ai_summary("ê´€ì‹¬ ì¢…ëª©",    ai_contexts["watchlist"], category="watchlist"),
    }

    # [D] ìµœì¢… ë°ì´í„° ì €ì¥
    logger.info("[Step D] Firebase ì €ì¥ ì‹œì‘")
    final_data = {
        "updated_at": now_str,
        "ai_summaries": ai_summaries,
        "news_feed": frontend_feed,
        "stock_data": stock_data_map,
        "portfolio_list": list(MY_PORTFOLIO.keys()),
        "watchlist_list": list(WATCHLIST.keys())
    }

    db_svc.save_final_feed(final_data)

    p_count = len(frontend_feed['portfolio'])
    w_count = len(frontend_feed['watchlist'])
    logger.info("[Success] Sync Complete. News: Port(%d), Watch(%d)", p_count, w_count)
        
def lambda_handler(event, context):
    print("ğŸš€ AWS Lambda í™˜ê²½ì—ì„œ ë™ê¸°í™” ì—”ì§„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    try:
        run_sync_engine_once()
        return {
            'statusCode': 200,
            'body': 'ë°ì´í„° ë™ê¸°í™” ì™„ë£Œ'
        }
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise e


if __name__ == "__main__":
    run_sync_engine_once()